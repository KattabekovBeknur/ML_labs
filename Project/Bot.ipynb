{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timeline', 'Life of Pi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migam\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2392: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "C:\\Users\\migam\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2326: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984375\n",
      "0.5952038527097449\n",
      "0.6079949036470775\n",
      "0.6600116429837792\n",
      "0.7476214574898785\n",
      "0.4904951885721117\n",
      "0.44547619047619047\n",
      "0.4754543990335675\n",
      "My Sweet Audrina\n",
      "['Timeline', 'Life of Pi', 'Timeline']\n",
      "1.0\n",
      "0.5296582330638058\n",
      "0.4103535353535354\n",
      "0.49630513277572097\n",
      "0.5196474870159081\n",
      "0.5894508220824011\n",
      "0.5075445297985344\n",
      "0.44263757062249454\n",
      "0.4608428677159327\n",
      "0.37179467088969353\n",
      "Prodigal Summer\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import urllib\n",
    "import os.path\n",
    "import os\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import subprocess\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "TOKEN = \"720923260:AAHHL8m8MgJ2tUKbFdPNd6j2JG2pCpj8fwA\"\n",
    "URL = \"https://api.telegram.org/bot{}/\".format(TOKEN)\n",
    "class RecommenderBot():\n",
    "    def get_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        content = response.content.decode(\"utf8\")\n",
    "        return content\n",
    "\n",
    "    def get_json_from_url(self, url):\n",
    "        content = self.get_url(url)\n",
    "        js = json.loads(content)\n",
    "        return js\n",
    "\n",
    "    def get_updates(self,offset=None):\n",
    "        url = URL + \"getUpdates?timeout=100\"\n",
    "        if offset:\n",
    "            url += \"&offset={}\".format(offset)\n",
    "        js = self.get_json_from_url(url)\n",
    "        return js\n",
    "\n",
    "    def get_last_update_id(self, updates):\n",
    "        update_ids = []\n",
    "        for update in updates[\"result\"]:\n",
    "            update_ids.append(int(update[\"update_id\"]))\n",
    "        return max(update_ids)\n",
    "    \n",
    "    def handle_updates(self, updates):\n",
    "        for update in updates[\"result\"]:\n",
    "#             print(update[\"message\"])\n",
    "            text = \"\"\n",
    "            if 'text' in update[\"message\"]:\n",
    "                text = update[\"message\"][\"text\"]\n",
    "            elif 'document' in update[\"message\"]:\n",
    "                if \"image\" in update['message']['document']['mime_type']:\n",
    "#                     print(update['message']['document']['file_id'])\n",
    "                    path = bot.getFile(update['message']['document']['file_id'])\n",
    "#                     print(path['file_path'])\n",
    "                    url = path['file_path']\n",
    "                    urlretrieve(url,os.path.abspath(str(update['message']['document']['file_name'])))\n",
    "                else:\n",
    "                    text = \"error\"\n",
    "            else:\n",
    "                text = \"error\"\n",
    "            chat = update[\"message\"][\"chat\"][\"id\"]\n",
    "            name = update[\"message\"][\"chat\"][\"first_name\"]\n",
    "            data = {}\n",
    "            old_message = {}\n",
    "            tick = [0]\n",
    "            list_books = []\n",
    "            if os.path.isfile('data.json'):\n",
    "                with open('data.json', 'r') as fp:\n",
    "                        data = json.load(fp)\n",
    "                        if str(name) in data and data[str(name)]!=None:\n",
    "                            list_books = data[str(name)]\n",
    "            if os.path.isfile('Old_message.json'):\n",
    "                with open('Old_message.json', 'r') as r:\n",
    "                        old_message = json.load(r)\n",
    "                        if str(name) in old_message:\n",
    "                            tick = old_message[str(name)]\n",
    "            if text == \"/start\":\n",
    "                self.send_message(\"Hello {}! Here you can find a book that is similar to your favorite one. Please type '/' to see all available commands.\".format(name), chat)\n",
    "            elif text == '/cancel':\n",
    "                old_message[str(name)] = [text]\n",
    "                with open(\"Old_message.json\", \"w\") as fm:\n",
    "                    json.dump(old_message, fm)\n",
    "                self.send_message('You cancelled an action',chat)\n",
    "            elif text ==\"/recommend_me\":\n",
    "                old_message[str(name)] = [text]\n",
    "#                 data[str(name)] = []\n",
    "#                 with open('data.json', 'w') as fp:\n",
    "#                     json.dump(data, fp)\n",
    "                with open(\"Old_message.json\", \"w\") as fm:\n",
    "                    json.dump(old_message, fm)\n",
    "                self.send_message(\"Please, type the name of the book that you have already read\",chat)\n",
    "            elif text !='' and tick[0]==\"/recommend_me\":\n",
    "#                 old_message[str(name)] = [text]\n",
    "                list_books.append(text)\n",
    "#                 with open(\"Old_message.json\", \"w\") as fm:\n",
    "#                     json.dump(old_message, fm)\n",
    "                if text in np.array(books['bookTitle']):\n",
    "                    data[str(name)] = list_books\n",
    "                    print(list_books)\n",
    "                    with open('data.json', 'w') as fp:\n",
    "                        json.dump(data, fp)\n",
    "                    yeahh = final_c(text,pearson(text))\n",
    "                    print(yeahh)\n",
    "                    self.send_message('Probably this is the book that you want - {}'.format(yeahh),chat)\n",
    "                else:\n",
    "                    self.send_message('Type correctly the name of the book',chat)\n",
    "            elif text == '/gift':\n",
    "                old_message[str(name)] = [text]\n",
    "                with open(\"Old_message.json\", \"w\") as fm:\n",
    "                    json.dump(old_message, fm)\n",
    "                self.send_message('Perhaps the person, whom you want to present a book, has used our service. Please, enter his or her name',chat)\n",
    "            elif text !='' and tick[0]=='/gift':\n",
    "                if text in data.keys():\n",
    "                    old_message[str(name)] = [text]\n",
    "                    with open(\"Old_message.json\", \"w\") as fm:\n",
    "                        json.dump(old_message, fm)\n",
    "                    self.send_message('Here is a list of books he/she read {}'.format(data[str(text)]),chat)\n",
    "                else:\n",
    "                    self.send_message('Unfortunately, we do not have such user:(',chat)\n",
    "            else:\n",
    "                self.send_message(\"Type '/' to view commands\", chat) \n",
    "    \n",
    "    def get_api(self, cnf):\n",
    "        auth = tweepy.OAuthHandler(cnf['consumer_key'], cnf['consumer_secret'])\n",
    "        auth.set_access_token(cnf['access_token'], cnf['access_token_secret'])\n",
    "        return tweepy.API(auth)\n",
    "\n",
    "    def get_last_chat_id_and_text(self, updates):\n",
    "        num_updates = len(updates[\"result\"])\n",
    "        last_update = num_updates - 1\n",
    "        text = updates[\"result\"][last_update][\"message\"][\"text\"]\n",
    "        chat_id = updates[\"result\"][last_update][\"message\"][\"chat\"][\"id\"]\n",
    "        return (text, chat_id)\n",
    "\n",
    "    def send_message(self, text, chat_id, reply_markup=None):\n",
    "        text = urllib.parse.quote_plus(text)\n",
    "        url = URL + \"sendMessage?text={}&chat_id={}&parse_mode=Markdown\".format(text, chat_id)\n",
    "        if reply_markup:\n",
    "            url += \"&reply_markup={}\".format(reply_markup)\n",
    "        self.get_url(url)\n",
    "\n",
    "    def build_keyboard(self, items):\n",
    "        keyboard = items#[[item] for item in items]\n",
    "        reply_markup = {\"keyboard\":keyboard, \"one_time_keyboard\": True}\n",
    "        return json.dumps(reply_markup)\n",
    "\n",
    "    def main(self):\n",
    "        last_update_id = None\n",
    "        self.__init__()\n",
    "        while True:\n",
    "            updates = self.get_updates(last_update_id)\n",
    "            if \"result\" in updates:\n",
    "                if len(updates[\"result\"]) > 0:\n",
    "                    last_update_id = self.get_last_update_id(updates) + 1\n",
    "                    self.handle_updates(updates)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        obj = RecommenderBot()\n",
    "        obj.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import all datasets\n",
    "\n",
    "books = pd.read_csv('Final_books.csv', sep='\\t', encoding='utf-8')\n",
    "books = books[['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'Genre','Content','IMG_URL']]\n",
    "users = pd.read_csv('Final_users.csv', sep='\\t', encoding='utf-8')\n",
    "users = users[['userID', 'Location', 'Age']]\n",
    "ratings = pd.read_csv('Final_ratings.csv', sep='\\t', encoding='utf-8')\n",
    "ratings = ratings[['userID', 'ISBN', 'bookRating']]\n",
    "books = books.dropna()\n",
    "books = books.reset_index()\n",
    "books = books[['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'Genre','Content','IMG_URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = users.loc[users['userID'] == userID[0]]\n",
    "# for i in range(1,len(userID)):\n",
    "#     u = u.append(users.loc[users['userID'] == userID[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookRating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0804106304</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060930535</th>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0743418174</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345370775</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440241073</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400034779</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0786868716</th>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440234743</th>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345417623</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0316769487</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bookRating\n",
       "ISBN                  \n",
       "0804106304         519\n",
       "0060930535         494\n",
       "0743418174         470\n",
       "0345370775         466\n",
       "0440241073         456\n",
       "1400034779         431\n",
       "0786868716         427\n",
       "0440234743         422\n",
       "0345417623         407\n",
       "0316769487         403"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_count = pd.DataFrame(ratings.groupby('ISBN')['bookRating'].count())\n",
    "rating_count.sort_values('bookRating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookAuthor</th>\n",
       "      <th>yearOfPublication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Content</th>\n",
       "      <th>IMG_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0345417623</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>MICHAEL CRICHTON</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>Science Fiction Fiction Suspense</td>\n",
       "      <td>In the middle of the New Mexico desert, a vac...</td>\n",
       "      <td>http://images.amazon.com/images/P/0345417623.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400034779</td>\n",
       "      <td>Kerosene</td>\n",
       "      <td>Alexander McCall Smith</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Anchor</td>\n",
       "      <td>Novel</td>\n",
       "      <td>Thirteen years after leaving the Philippines,...</td>\n",
       "      <td>http://images.amazon.com/images/P/1400034779.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0743418174</td>\n",
       "      <td>The Years of Rice and Salt</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Washington Square Press</td>\n",
       "      <td>Alternate history Science Fiction Speculative...</td>\n",
       "      <td>The novel is set in various locations around ...</td>\n",
       "      <td>http://images.amazon.com/images/P/0743418174.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0345370775</td>\n",
       "      <td>The Earth House</td>\n",
       "      <td>Michael Crichton</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>Young adult literature</td>\n",
       "      <td>They hadn\\'t pictured themselves as the sort ...</td>\n",
       "      <td>http://images.amazon.com/images/P/0345370775.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0440241073</td>\n",
       "      <td>Land of the Living</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Dell Publishing Company</td>\n",
       "      <td>Speculative fiction Fantasy</td>\n",
       "      <td>The book concerns the quest of Hallblithe of ...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440241073.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                   bookTitle              bookAuthor  \\\n",
       "0  0345417623                    Timeline        MICHAEL CRICHTON   \n",
       "1  1400034779                    Kerosene  Alexander McCall Smith   \n",
       "2  0743418174  The Years of Rice and Salt         Jennifer Weiner   \n",
       "3  0345370775             The Earth House        Michael Crichton   \n",
       "4  0440241073          Land of the Living            John Grisham   \n",
       "\n",
       "   yearOfPublication                publisher  \\\n",
       "0             2000.0         Ballantine Books   \n",
       "1             2003.0                   Anchor   \n",
       "2             2002.0  Washington Square Press   \n",
       "3             1999.0         Ballantine Books   \n",
       "4             2002.0  Dell Publishing Company   \n",
       "\n",
       "                                               Genre  \\\n",
       "0                   Science Fiction Fiction Suspense   \n",
       "1                                              Novel   \n",
       "2   Alternate history Science Fiction Speculative...   \n",
       "3                             Young adult literature   \n",
       "4                        Speculative fiction Fantasy   \n",
       "\n",
       "                                             Content  \\\n",
       "0   In the middle of the New Mexico desert, a vac...   \n",
       "1   Thirteen years after leaving the Philippines,...   \n",
       "2   The novel is set in various locations around ...   \n",
       "3   They hadn\\'t pictured themselves as the sort ...   \n",
       "4   The book concerns the quest of Hallblithe of ...   \n",
       "\n",
       "                                             IMG_URL  \n",
       "0  http://images.amazon.com/images/P/0345417623.0...  \n",
       "1  http://images.amazon.com/images/P/1400034779.0...  \n",
       "2  http://images.amazon.com/images/P/0743418174.0...  \n",
       "3  http://images.amazon.com/images/P/0345370775.0...  \n",
       "4  http://images.amazon.com/images/P/0440241073.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated_books = pd.DataFrame(['0345417623', '1400034779', '0743418174', '0345370775', '0440241073'], index=np.arange(5), columns = ['ISBN'])\n",
    "most_rated_books_summary = pd.merge(most_rated_books, books, on='ISBN')\n",
    "most_rated_books_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookRating</th>\n",
       "      <th>ratingCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0804106304</th>\n",
       "      <td>3.063584</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060930535</th>\n",
       "      <td>3.609312</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0743418174</th>\n",
       "      <td>4.040426</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345370775</th>\n",
       "      <td>3.369099</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440241073</th>\n",
       "      <td>3.195175</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bookRating  ratingCount\n",
       "ISBN                               \n",
       "0804106304    3.063584          519\n",
       "0060930535    3.609312          494\n",
       "0743418174    4.040426          470\n",
       "0345370775    3.369099          466\n",
       "0440241073    3.195175          456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rating = pd.DataFrame(ratings.groupby('ISBN')['bookRating'].mean())\n",
    "average_rating['ratingCount'] = pd.DataFrame(ratings.groupby('ISBN')['bookRating'].count())\n",
    "average_rating.sort_values('ratingCount', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts1 = ratings['userID'].value_counts()\n",
    "# ratings = ratings[ratings['userID'].isin(counts1[counts1 >= 50].index)]\n",
    "# counts = ratings['bookRating'].value_counts()\n",
    "# ratings = ratings[ratings['bookRating'].isin(counts[counts >= 10].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20971, 3500)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0002005395</th>\n",
       "      <th>0002179687</th>\n",
       "      <th>0002261529</th>\n",
       "      <th>0002713276</th>\n",
       "      <th>0006374964</th>\n",
       "      <th>0006479650</th>\n",
       "      <th>0006485936</th>\n",
       "      <th>0006548180</th>\n",
       "      <th>0006716067</th>\n",
       "      <th>0006749151</th>\n",
       "      <th>...</th>\n",
       "      <th>9502801954</th>\n",
       "      <th>9507682074</th>\n",
       "      <th>958949479X</th>\n",
       "      <th>9681902548</th>\n",
       "      <th>9721030791</th>\n",
       "      <th>9810023847</th>\n",
       "      <th>9810026595</th>\n",
       "      <th>9871106181</th>\n",
       "      <th>B00005NCS7</th>\n",
       "      <th>B00009ANY9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN    0002005395  0002179687  0002261529  0002713276  0006374964  \\\n",
       "userID                                                               \n",
       "8              NaN         NaN         NaN         NaN         NaN   \n",
       "9              NaN         NaN         NaN         NaN         NaN   \n",
       "16             NaN         NaN         NaN         NaN         NaN   \n",
       "17             NaN         NaN         NaN         NaN         NaN   \n",
       "26             NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN    0006479650  0006485936  0006548180  0006716067  0006749151  \\\n",
       "userID                                                               \n",
       "8              NaN         NaN         NaN         NaN         NaN   \n",
       "9              NaN         NaN         NaN         NaN         NaN   \n",
       "16             NaN         NaN         NaN         NaN         NaN   \n",
       "17             NaN         NaN         NaN         NaN         NaN   \n",
       "26             NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN       ...      9502801954  9507682074  958949479X  9681902548  \\\n",
       "userID     ...                                                       \n",
       "8          ...             NaN         NaN         NaN         NaN   \n",
       "9          ...             NaN         NaN         NaN         NaN   \n",
       "16         ...             NaN         NaN         NaN         NaN   \n",
       "17         ...             NaN         NaN         NaN         NaN   \n",
       "26         ...             NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN    9721030791  9810023847  9810026595  9871106181  B00005NCS7  B00009ANY9  \n",
       "userID                                                                          \n",
       "8              NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "9              NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "16             NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "17             NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "26             NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 3500 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_pivot = ratings.pivot(index='userID', columns='ISBN').bookRating\n",
    "userID = ratings_pivot.index\n",
    "ISBN = ratings_pivot.columns\n",
    "print(ratings_pivot.shape)\n",
    "ratings_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(sstring):\n",
    "    index = 0\n",
    "    for i in range(0,len(books['bookTitle'])):\n",
    "        if sstring in books['bookTitle'][i]:\n",
    "            index = i\n",
    "            break\n",
    "    bones_ratings = ratings_pivot[str(books['ISBN'][index])]\n",
    "    similar_to_bones = ratings_pivot.corrwith(bones_ratings)\n",
    "    corr_bones = pd.DataFrame(similar_to_bones, columns=['pearsonR'])\n",
    "    corr_bones.dropna(inplace=True)\n",
    "    corr_summary = corr_bones.join(average_rating['ratingCount'])\n",
    "    c = corr_summary[corr_summary['ratingCount']>=100].sort_values('pearsonR', ascending=False).head(10)\n",
    "    return c.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson('The Neverending Story')\n",
    "# final_c('',pearson(''))#this what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_corr_to_bones = pd.DataFrame([ '0142002267'],# '044022165X', '006101351X', '0312278586', '0440222656', '0060987103', '0439064872', '0671021001', '0345370775'], \n",
    "#                                   index=np.arange(1), columns=['ISBN'])\n",
    "# corr_books = pd.merge(books_corr_to_bones, books, on='ISBN')\n",
    "# corr_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_c(string, array):\n",
    "    name = ''\n",
    "    q = books.loc[books['bookTitle'] == string]\n",
    "    q = q.reset_index()\n",
    "    txt = q['Content'][0]\n",
    "    max = 0\n",
    "    for i in range(0,len(array)):\n",
    "        b = books.loc[books['ISBN'] == array[i]]\n",
    "        b = b.reset_index()\n",
    "        try:\n",
    "            num = compare(b['Content'][0],txt)\n",
    "        except:\n",
    "            num = -1\n",
    "        if max<num and string!=b['bookTitle'][0]:\n",
    "            max = num\n",
    "            name = b['bookTitle'][0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migam\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_topics(doc_a):\n",
    "    doc_set = [doc_a]\n",
    "    texts = []\n",
    "    for i in doc_set:\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        texts.append(stopped_tokens)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=1, id2word = dictionary, passes=3)\n",
    "    top_topics = ldamodel.top_topics(corpus)\n",
    "    return top_topics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(sstring1, sstring2):\n",
    "    #сумма всех similarities\n",
    "    avg=0\n",
    "    #count of similarities\n",
    "    cnt1=0\n",
    "    #топики первого текста и второго\n",
    "    top_topics1 = extract_main_topics(sstring1)\n",
    "    top_topics2 = extract_main_topics(sstring2)\n",
    "    for i in range(0,20):\n",
    "        sim=0\n",
    "        max_avg=0\n",
    "        for j in range (0,20):\n",
    "            try:\n",
    "                first = top_topics1[0][0][i][1]+'.n.01'\n",
    "                second = top_topics2[0][0][j][1]+'.n.01'\n",
    "\n",
    "                cb = wordnet.synset(first)\n",
    "                ib = wordnet.synset(second)\n",
    "                sim =cb.wup_similarity(ib)\n",
    "                \n",
    "                if(sim>max_avg):\n",
    "                    max_avg=sim\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                first = top_topics1[0][0][i][1]+'.a.01'\n",
    "                second = top_topics2[0][0][j][1]+'.a.01'\n",
    "\n",
    "                cb = wordnet.synset(first)\n",
    "                ib = wordnet.synset(second)\n",
    "                sim =cb.wup_similarity(ib)\n",
    "               \n",
    "\n",
    "                if(sim>max_avg):\n",
    "                    max_avg=sim\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                first = top_topics1[0][0][i][1]+'.v.01'\n",
    "                second = top_topics2[0][0][j][1]+'.v.01'\n",
    "\n",
    "                cb = wordnet.synset(first)\n",
    "                ib = wordnet.synset(second)\n",
    "                sim =cb.wup_similarity(ib)\n",
    "               \n",
    "\n",
    "                if(sim>max_avg):\n",
    "                    max_avg=sim\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "        if(max_avg!=0):\n",
    "            cnt1+=1\n",
    "            avg+=max_avg\n",
    "    if(cnt1!=0):\n",
    "        print(avg/cnt1)\n",
    "        return avg/cnt1\n",
    "    else:\n",
    "        print('no sim')\n",
    "        return 'no sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstring1 = \"They reach their monumental size on a diet of wild pigs, deer, birds, turtles, capybara, caimans, and even jaguars. Anacondas are nonvenomous constrictors, coiling their muscular bodies around captured prey and squeezing until the animal asphyxiates. Jaws attached by stretchy ligaments allow them to swallow their prey whole, no matter the size, and they can go weeks or months without food after a big meal.\"\n",
    "\n",
    "sstring2 = \"They achieve their momentous size on an eating routine of wild pigs, deer, winged creatures, turtles, capybara, caimans, and even pumas. Boa constrictors are nonvenomous constrictors, winding their solid bodies around caught prey and crushing until the point when the creature suffocates. Jaws joined by stretchy tendons enable them to gulp down their prey, regardless of the size, and they can go weeks or months without sustenance after a major feast.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
